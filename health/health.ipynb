{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "if 'google.colab' in sys.modules:  # If in Google Colab environment\n",
    "    # Installing requisite packages\n",
    "    !pip install datasets transformers evaluate accelerate -U\n",
    "\n",
    "    # Mount google drive to enable access to data files\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "    # Change working directory to health\n",
    "    %cd /content/drive/MyDrive/LLM4BeSci/health"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Processing data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cece20f24fb86874"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7080dd104c658ec4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Reading in the .csv data\n",
    "dat = pd.read_csv('health.csv')\n",
    "dat "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "52e0b1bdcee151c9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Convert pandas dataframe to HF Dataset\n",
    "dat = Dataset.from_pandas(dat)\n",
    "dat"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d432e8e4833d50b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dat[0]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6d624d4d59822c9e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Defining model checkpoint\n",
    "model_ckpt = 'distilbert-base-uncased'\n",
    "\n",
    "# Tokenizing the dataset\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n",
    "\n",
    "print(f'Vocabulary size: {tokenizer.vocab_size}, max context length: {tokenizer.model_max_length}')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "45565d0aea802193"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Function to tokenize a batch of samples\n",
    "batch_tokenizer = lambda batch: tokenizer(batch['text'], padding=True, truncation=True)\n",
    "\n",
    "#  Tokenizing the dataset\n",
    "dat = dat.map(batch_tokenizer, batched=True)\n",
    "dat[0]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "380a264634653886"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Setting to torch format for input to model\n",
    "dat.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "dat"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e4e7cc2aa4ef10cd"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Loading the model for feature extraction"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7f76a69e06ad12da"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.manual_seed(42) # For reproducibility\n",
    "from transformers import AutoModel"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "380788ac9d152759"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Loading the model and moving it to the GPU if available\n",
    "if torch.cuda.is_available():  # for nvidia GPUs\n",
    "    device = torch.device('cuda')\n",
    "elif torch.backends.mps.is_available(): # for Apple Metal Performance Sharder (mps) GPUs\n",
    "    device = torch.device('mps')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "device"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4d46f6ee9569323"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Loading distilbert-base-uncased and moving it to the GPU if available\n",
    "model = AutoModel.from_pretrained(model_ckpt).to(device)\n",
    "f'Model inputs: {tokenizer.model_input_names}'"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fccb948a9c0449da"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def extract_features(batch):\n",
    "    # Each batch is a dictionary with keys corresponding to the feature names. We only need the input ids and attention masks\n",
    "    inputs = {k:v.to(device) for k, v in batch.items() if k in tokenizer.model_input_names}\n",
    "\n",
    "    # Tell torch not to build the computation graph during inference with `torch.no_grad()`\n",
    "    with torch.no_grad():\n",
    "        last_hidden_state = model(**inputs).last_hidden_state # Extract last hidden states\n",
    "\n",
    "    # Return vector for [CLS] token\n",
    "    return {\"hidden_state\": last_hidden_state[:,0].cpu().numpy()}\n",
    "\n",
    "# Extracting features. Features are extracted in batches of 8 samples to avoid running out of memory.\n",
    "dat = dat.map(extract_features, batched=True, batch_size=8)\n",
    "dat['hidden_state'].shape"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4ffde493ddc2580b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Predicting health perception with extracted features"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "56f3657ebd8b63e1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "74721a900e4b068e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# converting to pandas dataframe\n",
    "features = pd.DataFrame(dat['hidden_state'])\n",
    "features"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e27dfbd089027633"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Splitting the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, dat['labels'], test_size=.2, random_state=42)\n",
    "f'Train size: {len(X_train)}, test size: {len(X_test)}'"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f39454e0c89ee5a6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Scaling the data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Initializing ridge regression \n",
    "ridge = RidgeCV(alphas=[10 ** i for i in range(-5, 7)])\n",
    "\n",
    "# Fitting the model and evaluating performance\n",
    "ridge.fit(X_train, y_train)\n",
    "f'Test R2 = {ridge.score(X_test, y_test).round(2)}'"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a1ed81c07ac83c1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Predicting health perception with fine-tuning"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9781773b6a3599c5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "import evaluate"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "407774333bbb12b8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Splitting the data into train and test sets\n",
    "dat = dat.train_test_split(test_size=.2, seed=42)\n",
    "dat"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d334c67f17f6c467"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "type(dat['train'])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "382657be3ce30c3b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Loading distilbert-base-uncased and moving it to the GPU if available\n",
    "model = (AutoModelForSequenceClassification\n",
    "         .from_pretrained(model_ckpt, num_labels=1) # num_labels=1 for regression\n",
    "         .to(device))\n",
    "\n",
    "model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7bab8ccda81a8dcd"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Setting up training arguments for the trainer\n",
    "model_name = f\"{model_ckpt}-finetuned-health\"\n",
    "batch_size = 8\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=model_name,  # output directory to save training checkpoints\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    logging_strategy=\"epoch\", # log training metrics at every epoch\n",
    "    evaluation_strategy=\"epoch\", # evaluate at the end of every epoch\n",
    "    num_train_epochs=10, # number of times to iterate over the training data\n",
    "    optim='adamw_torch', # optimizer to use\n",
    ")\n",
    "\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    \"\"\"Computes the coefficient of determination (R2) on the test set\"\"\"\n",
    "    metric = evaluate.load(\"r_squared\")\n",
    "    preds, labels = eval_preds\n",
    "    return {\"r_squared\": metric.compute(predictions=preds, references=labels)}\n",
    "\n",
    "\n",
    "# Instantiating the trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dat['train'],\n",
    "    eval_dataset=dat['test'],\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# Training the model\n",
    "trainer.train()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "60d4a085896ea9ef"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
