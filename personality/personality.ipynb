{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "if 'google.colab' in sys.modules:\n",
    "    # Installing packages in Google Colab environment\n",
    "    !pip install datasets transformers\n",
    "\n",
    "    # Mounting google drive to enable access to data files\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "    # Changing working directory to personality\n",
    "    %cd /content/drive/MyDrive/LLM4BeSci/personality"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Processing data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e749ee8b43faad3f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7a12dea23ca8d2cf"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Loading data with pandas\n",
    "neo_items =  pd.read_csv('NEO_items.csv', usecols=['item', 'construct'])\n",
    "neo_items"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "980be06b6a355d17"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Converting into a HuggingFace dataset\n",
    "dat = Dataset.from_pandas(neo_items)\n",
    "dat"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aadb3057d6b58b3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Loading the tokenizer\n",
    "model_ckpt = 'distilbert-base-uncased'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n",
    "print(f'Vocabulary size: {tokenizer.vocab_size}, max context length: {tokenizer.model_max_length}')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7e9899764c20ff1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Tokenizing the text\n",
    "batch_tokenizer = lambda x: tokenizer(x['item'], padding=True, truncation=True)\n",
    "dat = dat.map(batch_tokenizer, batched=True, batch_size=None)\n",
    "print([tokenizer.decode(id) for id in dat['input_ids'][0]])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "af3d4b563e1417bc"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Setting the format of the dataset to torch tensors for passing to the model\n",
    "dat.set_format('torch', columns=['input_ids', 'attention_mask'])\n",
    "dat"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b59e8a62cd6224de"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "dat['input_ids'].shape"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bc8c8e442530952b",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Feature extraction"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7bc898c43652db8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModel"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6f0a90df92dae822"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Loading the model and moving it to the GPU if available\n",
    "if torch.cuda.is_available():  # for nvidia GPUs\n",
    "    device = torch.device('cuda')\n",
    "elif torch.backends.mps.is_available(): # for Apple Metal Performance Sharder (mps) GPUs\n",
    "    device = torch.device('mps')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "device"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e379819528ec61ad"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Loading the model\n",
    "model = AutoModel.from_pretrained('distilbert-base-uncased').to(device)\n",
    "f'Model inputs: {tokenizer.model_input_names}'"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "698edca117e2b80f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def extract_features(batch):\n",
    "    \"\"\"Extract features from a batch of items\"\"\"\n",
    "    inputs = {k:v.to(device) for k, v in batch.items() if k in tokenizer.model_input_names}\n",
    "    with torch.no_grad():\n",
    "        last_hidden_state = model(**inputs).last_hidden_state\n",
    "        return {\"hidden_state\": last_hidden_state[:,0].cpu().numpy()}\n",
    "\n",
    "\n",
    "dat = dat.map(extract_features, batched=True, batch_size=8)\n",
    "dat"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9fb725d27733027d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dat['input_ids'].shape"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5d51a6a9c3553071"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Comparing predicted and observed construct similarities"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "899b22bd5abc48b3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5afc733c39662433"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Converting the hidden state into a data frame for easy manipulation\n",
    "features = pd.DataFrame(dat['hidden_state'])\n",
    "features"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b2c6bbdf5010bc43"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Calculating the cosine similarity between construct embeddings\n",
    "sims = pd.DataFrame(\n",
    "    cosine_similarity(features),\n",
    "    index=neo_items['item'],\n",
    "    columns=neo_items['item'],\n",
    ")\n",
    "sims"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aa04659949c5500"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Loading observed correlations and pivoting to a correlation matrix\n",
    "sims_observed = pd.read_csv('item_corrs.csv')\n",
    "sims_observed"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3abb71c4bfdef9c9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Pivoting to a correlation matrix for easy comparison with predicted correlations\n",
    "sims_observed = sims_observed.pivot(index='text_i', columns='text_j', values='cor')\n",
    "sims_observed"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "76e29fb070d5bdf9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Aligning rows and columns the predicted and observed correlations\n",
    "sims, sims_observed = sims.align(sims_observed)\n",
    "\n",
    "\n",
    "def lower_triangle_flat(df):\n",
    "    \"\"\"Takes the lower triangle of a dataframe and flattens it into a vector\"\"\"\n",
    "    rows, cols = np.triu_indices(len(df), k=1)  # k=1 to exclude the diagonal (self-similarities)\n",
    "    return pd.Series(df.values[rows, cols])\n",
    "\n",
    "\n",
    "sims, sims_observed = lower_triangle_flat(sims), lower_triangle_flat(sims_observed)\n",
    "\n",
    "# Correlation between predicted and observed\n",
    "print(f'r: {sims.corr(sims_observed).round(2)}')\n",
    "print(f'r of absolute values: {sims.abs().corr(sims_observed.abs()).round(2)}')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fbead662dbef9450"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
